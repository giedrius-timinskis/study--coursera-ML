function p = predictOneVsAll(all_theta, X)
%PREDICT Predict the label for a trained one-vs-all classifier. The labels 
%are in the range 1..K, where K = size(all_theta, 1). 
%  p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions
%  for each example in the matrix X. Note that X contains the examples in
%  rows. all_theta is a matrix where the i-th row is a trained logistic
%  regression theta vector for the i-th class. You should set p to a vector
%  of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2
%  for 4 examples) 

m = size(X, 1);
num_labels = size(all_theta, 1);

% You need to return the following variables correctly 
p = zeros(size(X, 1), 1);

% Add ones to the X data matrix
X = [ones(m, 1) X];

% ====================== YOUR CODE HERE ======================
% Instructions: Complete the following code to make predictions using
%               your learned logistic regression parameters (one-vs-all).
%               You should set p to a vector of predictions (from 1 to
%               num_labels).
%
% Hint: This code can be done all vectorized using the max function.
%       In particular, the max function can also return the index of the 
%       max element, for more information see 'help max'. If your examples 
%       are in rows, then, you can use max(A, [], 2) to obtain the max 
%       for each row.
%       

% For each row of X (written symbol pixel values),
% apply a theta (generated by our oneVsAll classifier)
% and see which theta returns the highest number.
% The highest number will mean that it predicted that
% particular written symbol (in this example numbers from 1-10)

% Challenges 1: How do I apply a theta to a row of X?
% SOLVED: L52
% Challenges 2:How do I write a vectorized implementation of the double for loop
% SOLVED: L71
% =========================================================================

for currentLetterRow = 1:m
    % Create an intermediate 2D matrix that will hold the calculated
    % valuesfor each symbol
    % First column will hold the probability
    % Second value will hold the label number (1-10 in this case)
    probabilitiesForThisRow = zeros(num_labels, 1);
    for currentClassifier = 1:num_labels
        currentClassifierProbability = sum(X(currentLetterRow, :) .* all_theta(currentClassifier, :));
        probabilitiesForThisRow(currentClassifier) = currentClassifierProbability;
    end
    
    % Get the classifierIndex that predicted the highest value for this row
    % Note that we don't use the first value given to us by the max
    % function, which is not useful to us in this example (because it
    % returns the highest value, we only care about the index of classifier
    % that predicted the highest value.
    [~, classifierIndex] = max(probabilitiesForThisRow);
    
    % Return the predicted classified for this row
    p(currentLetterRow) = classifierIndex;
end

end

% OR instead of doing all the crap above manually use this:
% "Inspired" by https://github.com/jmiller656/Coursera-Machine-Learning/blob/master/machine-learning-ex3/ex3/predictOneVsAll.m
% max(sigmoid(X * all_theta'),[],2)
